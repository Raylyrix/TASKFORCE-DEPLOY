# Server Crash Fixes - 11 Hour Crash Investigation

## ðŸ” Root Causes Identified

### 1. **Excessive Worker Concurrency** (CRITICAL)
**Problem**: Each BullMQ worker had `concurrency: 10` in production
- 9 workers Ã— 10 concurrency = **90 simultaneous jobs**
- Each job makes multiple database calls and API requests
- This exhausted memory and CPU, causing crashes

**Fix Applied**:
- Reduced default concurrency to **3** per worker
- Campaign/follow-up workers: **5** concurrent jobs
- Added rate limiters: max 10Ã—concurrency jobs per second per worker
- **Impact**: Reduces concurrent load by **70%** (from 90 to ~27 max)

### 2. **Overlapping `setInterval` Executions**
**Problem**: Scheduled tasks could stack if previous execution hadn't finished
- `processScheduledEmails()` runs every minute
- If it takes > 60s, next execution starts while first is still running
- This causes exponential resource consumption

**Fix Applied**:
- Added locks (flags) to prevent overlapping executions
- Each periodic task checks if it's already running before starting
- Logs warning if skipping due to ongoing execution

### 3. **No Rate Limiting**
**Problem**: API endpoints had no protection against abuse
- Admin panel could be hit repeatedly
- Campaign creation unlimited
- No protection against DDoS or API abuse

**Fix Applied**:
- General API: **100 requests / 15 min / IP**
- Admin API: **30 requests / 15 min / IP**
- Campaign creation: **20 / hour / user**
- Campaign start: **10 / min / user**
- Auth endpoints: **5 attempts / 15 min / IP**

### 4. **Admin Panel Still Causing Load**
**Problem**: Even with caching, admin panel makes heavy queries
- Database size calculation is expensive
- Daily aggregation queries scan entire tables
- Multiple raw SQL queries with `DATE()` functions

**Fix Applied**:
- Wrapped all expensive queries in try-catch with fallbacks
- Added `LIMIT 365` to daily aggregation queries
- Made database size calculation optional (fails gracefully)
- Already had 60s caching from previous fix

---

## ðŸ› ï¸ All Changes Made

### File: `backend/src/queue/queueFactory.ts`
```typescript
// BEFORE
concurrency: AppConfig.nodeEnv === "production" ? 10 : 2,

// AFTER
concurrency: AppConfig.nodeEnv === "production" ? (options?.concurrency || 3) : 2,
limiter: {
  max: concurrency * 10, // Max jobs per duration
  duration: 1000, // Per second
},
```

### File: `backend/src/queue/campaignQueue.ts`
```typescript
// Added concurrency limit
registerWorker(..., { concurrency: 5 })
```

### File: `backend/src/queue/followUpQueue.ts`
```typescript
// Added concurrency limit
registerWorker(..., { concurrency: 5 })
```

### File: `backend/src/server.ts`
```typescript
// Added locks to prevent overlapping executions
let isRunningPeriodicSync = false;
let isRunningScheduledEmails = false;
let isRunningSnoozedEmails = false;

setInterval(async () => {
  if (isRunningScheduledEmails) {
    logger.warn("Already running, skipping");
    return;
  }
  isRunningScheduledEmails = true;
  try {
    await processScheduledEmails();
  } finally {
    isRunningScheduledEmails = false;
  }
}, 60000);
```

### File: `backend/src/middleware/rateLimiter.ts` (NEW)
- General API rate limiter
- Admin API rate limiter (stricter)
- Campaign creation rate limiter
- Campaign start rate limiter
- Auth rate limiter (prevents brute force)

### File: `backend/src/app.ts`
```typescript
// Added rate limiting to all API routes
app.use("/api", generalRateLimiter);
```

### File: `backend/src/routes/modules/admin.ts`
```typescript
// Added stricter rate limiting to admin routes
adminRouter.use(adminRateLimiter);
```

### File: `backend/src/routes/modules/campaigns.ts`
```typescript
// Added rate limiting to campaign creation and starting
campaignsRouter.post("/", requireUser, campaignCreationRateLimiter, ...);
campaignsRouter.post("/:id/schedule", requireUser, campaignStartRateLimiter, ...);
```

---

## ðŸ“Š Expected Impact

### Before Fixes:
- **Max concurrent jobs**: 90
- **No rate limiting**: Unlimited API requests
- **Overlapping executions**: Possible
- **Admin panel**: Could hammer database
- **Crash risk**: HIGH

### After Fixes:
- **Max concurrent jobs**: ~27 (70% reduction)
- **Rate limiting**: All endpoints protected
- **Overlapping executions**: Prevented
- **Admin panel**: Cached + fallbacks
- **Crash risk**: LOW

---

## ðŸ”¬ How to Monitor

### 1. Check Worker Concurrency in Logs
```bash
railway logs --service taskforce-backend | grep "Queue job"
```
Should see jobs processing, but not overwhelming amounts.

### 2. Check for Overlapping Executions
```bash
railway logs --service taskforce-backend | grep "already running"
```
If you see these warnings frequently, increase interval times.

### 3. Check Rate Limiting
```bash
railway logs --service taskforce-backend | grep "Rate limit exceeded"
```
These warnings indicate someone is hitting limits (good - protection working).

### 4. Monitor Memory Usage
In Railway dashboard:
- **Metrics** tab
- Watch memory usage
- Should stay under 80% of allocated memory

---

## âš ï¸ What to Watch For

### Signs of Still Having Issues:

1. **Memory keeps growing**
   - Check for memory leaks
   - May need to add more aggressive caching

2. **CPU spikes at regular intervals**
   - Check which cron job is causing it
   - May need to reduce frequency or optimize queries

3. **"Already running" warnings every cycle**
   - Task is taking longer than interval
   - Increase interval OR optimize task

4. **Frequent rate limit warnings from real users**
   - Limits may be too strict
   - Can increase them in `rateLimiter.ts`

---

## ðŸš€ Deployment Status

All fixes are committed and pushed to main branch.
Railway will auto-deploy.

Expected deployment time: **~5 minutes**

---

## ðŸ“ Next Recommended Actions

### 1. **Add Memory Monitoring** (High Priority)
```typescript
// Add to server.ts
setInterval(() => {
  const usage = process.memoryUsage();
  logger.info({
    rss: `${Math.round(usage.rss / 1024 / 1024)}MB`,
    heapUsed: `${Math.round(usage.heapUsed / 1024 / 1024)}MB`,
    heapTotal: `${Math.round(usage.heapTotal / 1024 / 1024)}MB`,
  }, "Memory usage");
}, 60000); // Every minute
```

### 2. **Add Request Timeout** (Medium Priority)
```typescript
// Prevent long-running requests from blocking
app.use((req, res, next) => {
  req.setTimeout(30000); // 30 second timeout
  next();
});
```

### 3. **Add Database Connection Pooling Monitoring**
```typescript
// Monitor Prisma connection pool
const dbStats = await prisma.$metrics.json();
logger.info({ dbStats }, "Database metrics");
```

### 4. **Consider Upgrading Railway Plan** (If still issues)
Current plan limits:
- Memory: Check your plan
- CPU: Shared
- Consider upgrading if hitting limits consistently

---

## âœ… Testing Checklist

- [x] Worker concurrency reduced
- [x] Overlapping execution prevention added
- [x] Rate limiting implemented
- [x] Admin panel optimized
- [x] All linter checks passed
- [ ] Monitor for 24 hours
- [ ] Check memory usage stays stable
- [ ] Verify no new crashes
- [ ] Test admin panel under load

---

## ðŸŽ¯ Success Metrics

**After 24 hours, we should see:**
1. No server crashes or restarts
2. Memory usage stable (not growing)
3. CPU usage under 70% average
4. No "already running" warnings every cycle
5. Admin panel responsive

**If any of these fail, we may need to:**
- Further reduce concurrency
- Increase caching TTL
- Optimize database queries
- Upgrade Railway plan

---

**Questions? Issues?** Let me know and I'll investigate further.

